<!DOCTYPE html>
<html lang="en">

	<head>

		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
		<meta name="description" content="">
		<meta name="author" content="">

		<title>UW LING 575 (Winter 2020)</title>

		<!-- Bootstrap core CSS -->
		<link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

		<!-- Custom styles for this template -->
		<link href="css/scrolling-nav.css" rel="stylesheet">

	</head>

	<body id="page-top">

		<!-- Navigation -->
		<nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top" id="mainNav">
			<div class="container">
				<a class="navbar-brand js-scroll-trigger" href="#page-top">LING 575: Analyzing Neural Language Models [Win '20]</a>
				<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
					<span class="navbar-toggler-icon"></span>
				</button>
				<div class="collapse navbar-collapse" id="navbarResponsive">
					<ul class="navbar-nav ml-auto">
						<li class="nav-item">
							<a class="nav-link js-scroll-trigger" href="#information">Information</a>
						</li>
						<li class="nav-item">
							<a class="nav-link js-scroll-trigger" href="#policies">Policies</a>
						</li>
						<li class="nav-item">
							<a class="nav-link js-scroll-trigger" href="#schedule">Schedule</a>
						</li>
						<li class="nav-item">
							<a class="nav-link js-scroll-trigger" href="#reading">Reading List</a>
						</li>
					</ul>
				</div>
			</div>
		</nav>

		<!--
		<header class="bg-primary text-white">
			<div class="container text-center">
				<h1>Welcome to Scrolling Nav</h1>
				<p class="lead">A landing page template freshly redesigned for Bootstrap 4</p>
			</div>
		</header>
		-->

		<section id="information">
			<div class="container">
				<div class="row">
					<div class="col-lg-12 mx-auto">
						<h2>Course Description</h2>
						<p class="lead">
						Two recent trends in NLP---the application of deep neural networks and the use of transfer learning---have resulted in many models that achieve high performance on important tasks but whose behavior on those tasks is difficult to interpret.  In this seminar, we will look at methods inspired by linguistics and cognitive science for analyzing what large neural language models have in fact learned: diagnostic/probing classifiers, adversarial test sets, and artificial languages, among others.  Particular attention will be paid to probing these models' _semantic_ knowledge, which has received comparably little attention compared to their syntactic knowledge.  Students will acquire relevant skills and (in small groups) design and execute a linguistically-informed analysis experiment, resulting in a report in the form of a publishable conference paper.
						</p>

						<table class="table">
							<thead>
								<tr>
								<th>Days</th>
								<th>Time</th>
								<th>Location</th>
								</tr>
							</thead>
							<tbody>
								<tr>
									<td>Thursday</td>
									<td>3:30 - 5:50 PM</td>
									<td><a href="https://uw.edu/maps/?sav" target="_blank">Savery</a> 137</td>
								</tr>
							</tbody>
						</table>

						<h2 class="pt-2">Teaching Staff</h2>
						<table class="table">
							<thead>
								<tr>
									<th>Role</th>
									<th>Name</th>
									<th>Office</th>
									<th>Office Hours</th>
								</tr>
							</thead>
							<tbody>
								<tr>
									<td>Instructor</td>
									<td><a href="https://shane.st" target="_blank">Shane Steinert-Threlkeld</a></td>
									<td>Guggenheim 418-D (and Zoom)</td>
									<td>Tuesday, 2:30 - 4:30 PM</td>
								</tr>
							</tbody>
						</table>


						<h2 class="pt-2">Prerequisites</h2>
						<ul>
							<li>Mathematical background: linear algebra, multivariable calculus</li>
							<li>LING 570 or 571</li>
							<li>LING 572 recommended, but not required</li>
							<li>One other linguistics course (not necessarily at UW)</li>
							<li>Programming in Python</li>
							<li>Linux/Unix Commands</li>
						</ul>

						<h2 class="pt-2">Course Resources</h2>

						<ul>
							<li><a href="https://canvas.uw.edu/courses/1356332" target="_blank">Canvas</a>: lecture recordings, discussion board, homework submission / grading</li>
							<li>Zoom Meeting Room: <a href="https://washington.zoom.us/my/clingzoom" target="_blank">https://washington.zoom.us/my/clingzoom</a></li>
							<li><a href="https://vervet.ling.washington.edu/db/accountrequest-form.php" target="_blank">Patas Account Request</a></li>
							<li><a href="../../571/aut19/welcome_to_patas_1920.pdf" target="_blank">Computing Resources Orientation</a></li>
							<li><a href="https://wiki.ling.washington.edu/bin/view.cgi/Main/CondorClusterHomepage" target="_blank">Condor Wiki Pages</a></li>
						</ul>

						<!-- <p><strong>N.B.:</strong> All homework grading will take place on the patas cluster using Condor, so your code must run there.  I strongly encourage you to ensure you have an account set up by the time of the first course meeting.</p> -->
					</div>
				</div>
			</div>
		</section>

		<section id="policies" class="bg-light">
			<div class="container">
				<div class="row">
					<div class="col-lg-12 mx-auto">
						<h2>Policies</h2>

						<p class="lead">As a project-oriented, student-driven, seminar-style class, active participation---in the classroom, or in Zoom, as well as on Canvas---is expected.</p>
						<p>All student work will be carried out in small groups.  Groups are free to divide up work as they see fit, but will be required to explain the division of labor with their final project.  Except under rare circumstances, every member of a group will receive the same grades.</p>

						<h2 class="pt-2">Grading</h2>

						<p>The distribution of grades for the final grade will be:</p>
						<ul>
							<li>Final project paper: 50%</li>
							<li>Project proposal: 10%</li>
							<li>Special topic presentation: 20%</li>
							<li>Final project presentation: 10%</li>
							<li>Class participation: 10%</li>
						</ul>

						<h2 class="pt-2">Communication</h2>
						<p>Any questions concerning course content and logistics should be posted on the Canvas discussion board.  If a more personal issue arises, you can email me personally; include &quot;LING575&quot; in the subject line.  You can expect responses from teaching staff within 24 hours, but only during normal business hours, and excluding weekends.</p>

						<h2 class="pt-2">Religious Accommodation</h2>
						<p>Washington state law requires that UW develop a policy for accommodation of student absences or significant hardship due to reasons of faith or conscience, or for organized religious activities. The UW’s policy, including more information about how to request an accommodation, is available at <a href="https://registrar.washington.edu/staffandfaculty/religious-accommodations-policy/" target="_blank">Religious Accommodations Policy (https://registrar.washington.edu/staffandfaculty/religious-accommodations-policy/)</a>. Accommodations must be requested within the first two weeks of this course using the <a href="https://registrar.washington.edu/students/religious-accommodations-request/" target="_blank">Religious Accommodations Request form (https://registrar.washington.edu/students/religious-accommodations-request/)</a>.</p>

						<h2 class="pt-2">Access and Accommodations</h2>
						<p>Your experience in this class is important to me. If you have already established accommodations with Disability Resources for Students (DRS), please communicate your approved accommodations to me at your earliest convenience so we can discuss your needs in this course.</p>
						<p>If you have not yet established services through DRS, but have a temporary health condition or permanent disability that requires accommodations (conditions include but not limited to; mental health, attention-related, learning, vision, hearing, physical or health impacts), you are welcome to contact DRS at 206-543-8924 or uwdrs@uw.edu or disability.uw.edu. DRS offers resources and coordinates reasonable accommodations for students with disabilities and/or temporary health conditions.  Reasonable accommodations are established through an interactive process between you, your instructor(s) and DRS.  It is the policy and practice of the University of Washington to create inclusive and accessible learning environments consistent with federal and state law.</p>

						<h2 class="pt-2">Safety</h2>
						<p>Call SafeCampus at 206-685-7233 anytime – no matter where you work or study – to anonymously discuss safety and well-being concerns for yourself or others. SafeCampus’s team of caring professionals will provide individualized support, while discussing short- and long-term solutions and connecting you with additional resources when requested.</p>
					</div>
				</div>
			</div>
		</section>


		<section id="schedule">
			<div class="container">
				<div class="row">
					<div class="col-lg-12 mx-auto">

						<h2>Schedule</h2>

						<br />

						<table class="table">
							<thead>
								<tr>
									<th width="10%">Date</th>
									<th>Topics</th>
									<th width="45%">Suggested Readings</th>
									<th width="20%">Additional info</th>
								</tr>
							</thead>
							<tbody>
								<tr>
									<td>Jan 9</td>
									<td>
										<a href="slides/1_Intro.pdf" target="_blank">
										Introduction to Transfer Learning in NLP
										<br />
										Course Overview
										</a>
									</td>
									<td>
										<a href="https://thegradient.pub/nlp-imagenet/" target="_blank">NLP's ImageNet Moment Has Arrived</a>
										<br />
										<a href="https://thegradient.pub/nlps-clever-hans-moment-has-arrived/" target="_blank">NLP's Clever Hans Moment Has Arrived</a>
										<!--
										<br />
										something here about motivations for analysis work...
										-->
									</td>
									<td>
										<a href="hw1.html" target="_blank">HW1</a> (group formation) out
									</td>
								</tr>
								<tr>
									<td>Jan 16</td>
									<td>
										<a href="slides/2_LMs.pdf" target="_blank">Language Models</a>
									</td>
									<td>
										<a href="http://arxiv.org/abs/1802.05365" target="_blank">Deep contextualized word representations</a> (ELMo paper)
										<br />
										<a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank">Understanding LSTMs</a>
										<br />
										<a href="https://arxiv.org/abs/1810.04805" target="_blank">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a>
										<br />
										<a href="https://nlp.seas.harvard.edu/2018/04/03/attention.html" target="_blank">The Annotated Transformer</a>
										<br />
										<a href="http://jalammar.github.io/illustrated-transformer/" target="_blank">The Illustrated Transformer</a>
									</td>
									<td>
										HW1 due
									</td>
								</tr>
								<tr>
									<td>Jan 23</td>
									<td>
										<a href="slides/3_methods.pdf" target="_blank">Analysis Methods</a>
									</td>
									<td>
										Belinkov and Glass, &quot;<a href="https://www.mitpressjournals.org/doi/full/10.1162/tacl_a_00254" target="_blank">Analysis Methods in Neural Language Processing: A Survey</a>&quot;
										<br />
										NAACL 2019 <a href="https://docs.google.com/presentation/d/1fIhGikFPnb7G5kr58OvYC3GN4io7MznnM0aAgadvJfc/edit?ts=5c8d09e7#slide=id.g569f436ced_0_26" target="_blank">Tutorial on Transfer Learning in NLP</a> (slides 73-96)
										<br />
										<br />
										<a href="https://www.mitpressjournals.org/doi/10.1162/tacl_a_00115" target="_blank"> Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies</a> (original linguistic task paper)
										<br />
										<a href="https://www.aclweb.org/anthology/N19-1112/" target="_blank">Linguistic Knowledge and Transferability of Contextual Representations</a> (prototypical probing paper)
										<br />
										<a href="https://www.aclweb.org/anthology/W19-4828/" target="_blank">What Does BERT Look at? An Analysis of BERT’s Attention</a> (prototypical attention paper)
									</td>
									<td>
										<a href="proposals.html" target="_blank">Proposal guidelines</a> out [<a href="slides/3_proposals.pdf" target="_blank">slides</a>]
									</td>
								</tr>
								<tr>
									<td>Jan 30</td>
									<td>
										<strong>Guest lecture:</strong> <a href="https://rudinger.github.io/" target="_blank">Rachel Rudinger</a> on the Universal Decompositional Semantics Initiative
										<br />
										[<a href="slides/Rudinger_GuestLecture.pdf" target="_blank">slides</a>, <a href="https://decomp.io" target="_blank">decomp.io</a>]
										<br />
										<a href="slides/4_data.pdf" target="_blank">Other datasets</a>
									</td>
									<td>
										<a href="https://arxiv.org/pdf/1909.13851.pdf" target="_blank">The Universal Decompositional Semantics Dataset and Decomp Toolkit</a>
										<br />
									</td>
									<td>
										Presentation sign-up
									</td>
								</tr>
								<tr>
									<td>Feb 6</td>
									<td>
										<a href="slides/5_resources.pdf" target="_blank">Technical resources</a>
										<br />
										<a href="slides/5_process.pdf" target="_blank">How to write an NLP paper</a>
										<br />
										<a href="https://github.com/shanest/allennlp-bert-example" target="_blank">AllenNLP BERT probing demo</a>
									</td>
									<td>
										HuggingFace Transformers
										[<a href="https://arxiv.org/abs/1910.03771" target="_blank">paper</a>, <a href="https://huggingface.co/transformers/" target="_blank">web</a>]
										<br />
										AllenNLP [<a href="https://arxiv.org/abs/1803.07640" target="_blank">paper</a>, <a href="https://allennlp.org/" target="_blank">web</a>]
										<br />
										<a href="patas-gpu.pdf" target="_blank">Using GPUs on the patas cluster</a>
										<!--
										<br />
										Jiant?
										<br />
										Experiment management tools???
										-->
									</td>
									<td>
										Proposal due
									</td>
								</tr>
								<tr>
									<td>Feb 13</td>
									<td>
										Special Topic 1: Hate speech classification using BERT (Courtney and David; Group 2)
									</td>
									<td>
										<a href="https://www.aclweb.org/anthology/N16-2013/" target="_blank">Hateful Symbols or Hateful People? Predictive Features for Hate Speech Detection on Twitter</a>
										<br />
										<a href="https://ieeexplore.ieee.org/document/8955559" target="_blank">MC-BERT4HATE: Hate Speech Detection using Multi-channel BERT for Different Languages and Translations</a>
										<br />
										(Optional) <a href="https://arxiv.org/pdf/1812.09355.pdf" target="_blank">What Is One Grain of Sand in the Desert? Analyzing Individual Neurons in Deep NLP Models</a>
									</td>
									<td>
									</td>
								</tr>
								<tr>
									<td class="border-0"></td>
									<td class="border-0">
										Special Topic 2: Evaluating NLI models using formal logic (Group 5)
									</td>
									<td class="border-0">
										<a href="https://arxiv.org/abs/1909.07521" target="_blank">Probing Natural Language Inference Models through Semantic Fragments</a>
										<br />
										<a href="https://arxiv.org/abs/1905.05704" target="_blank">A logical-based corpus for cross-lingual evaluation</a>
									</td>
									<td class="border-0">
									</td>
								</tr>
								<tr>
									<td>Feb 20</td>
									<td>
										Special Topic 1:
										<br />
										Special Topic 2:
									</td>
									<td>
									</td>
									<td>
									</td>
								</tr>
								<tr>
									<td>Feb 27</td>
									<td>
										Special Topic 1:
										<br />
										Special Topic 2:
									</td>
									<td>
									</td>
									<td>
									</td>
								</tr>
								<tr>
									<td>Mar 5</td>
									<td>
										Special Topic 1:
										<br />
										Special Topic 2:
									</td>
									<td>
									</td>
									<td>
									</td>
								</tr>
								<tr>
									<td>Mar 12</td>
									<td>
										Project presentation fest!
									</td>
									<td>
									</td>
									<td>
									</td>
								</tr>
							</tbody>
						</table>
					</div>
				</div>
			</div>
		</section>

		<section id="reading" class="bg-light">
			<div class="container">
				<div class="row">
					<div class="col-lg-12 mx-auto">
						<h2>Reading List</h2>
						<p class="lead">This is a list of a snapshot of some papers on interpretability / analysis of language models, reflecting my knowledge of the state of the field circa December 2019.  The field is large and fast-growing, so this is by no means exhaustive.  To find even more literature, I recommend:</p>
						<ul>
							<li>The references in these papers</li>
							<li>BlackboxNLP proceedings: <a href="https://www.aclweb.org/anthology/volumes/W18-54/" target="_blank">2018</a>, <a href="https://www.aclweb.org/anthology/volumes/W19-48/" target="_blank">2019</a></li>
							<li>Search terms in Google Scholar/SemanticScholar: probing, analysis, diagnostic classifiers</li>
						</ul>
						<p>NB: the list below is an <span style="font-family: courier">iframe</span>, so make sure to scroll to see everything.</p>
						<!--
						<script src="https://bibbase.org/show?bib=https%3A%2F%2Fwww.shane.st%2Fteaching%2F575%2Fwin20%2FMachineLearning-interpretability.bib&jsonp=1"></script>
						-->
						<div class="embed-responsive  embed-responsive-1by1">
							<iframe class="embed-responsive-item" src="https://bibbase.org/show?bib=https%3A%2F%2Fwww.shane.st%2Fteaching%2F575%2Fwin20%2FMachineLearning-interpretability.bib"></iframe> 
						</div>
					</div>
				</div>
			</div>
		</section>

		<!-- Bootstrap core JavaScript -->
		<script src="vendor/jquery/jquery.min.js"></script>
		<script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

		<!-- Plugin JavaScript -->
		<script src="vendor/jquery-easing/jquery.easing.min.js"></script>

		<!-- Custom JavaScript for this theme -->
		<script src="js/scrolling-nav.js"></script>

		<!-- Google analytics -->
		<script>
			(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
				(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
					m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
			})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

			ga('create', 'UA-6353489-4', 'auto');
			ga('send', 'pageview');
		</script>

	</body>

</html>
