@inproceedings{andreasMeasuringCompositionalityRepresentation2019,
  title = {Measuring {{Compositionality}} in {{Representation Learning}}},
  booktitle = {International {{Conference}} of {{Learning Representations}}},
  author = {Andreas, Jacob},
  date = {2019},
  eprint = {1902.07181},
  eprinttype = {arxiv},
  url = {https://openreview.net/forum?id=HJz05o0qK7},
  abstract = {Many machine learning algorithms represent input data with vector embeddings or discrete codes. When inputs exhibit compositional structure (e.g. objects built from parts or procedures from subroutines), it is natural to ask whether this compositional structure is reflected in the the inputs' learned representations. While the assessment of compositionality in languages has received significant attention in linguistics and adjacent fields, the machine learning literature lacks general-purpose tools for producing graded measurements of compositional structure in more general (e.g. vector-valued) representation spaces. We describe a procedure for evaluating compositionality by measuring how well the true representation-producing model can be approximated by a model that explicitly composes a collection of inferred representational primitives. We use the procedure to provide formal and empirical characterizations of compositional structure in a variety of settings, exploring the relationship between compositionality and learning dynamics, human judgments, representational similarity, and generalization.},
  keywords = {method: tree reconstruction error,phenomenon: compositionality},
  file = {/Users/shanest/sync/library/Andreas/2019/Andreas - 2019 - Measuring Compositionality in Representation Learn.pdf}
}

@article{brightonUnderstandingLinguisticEvolution2006,
  title = {Understanding {{Linguistic Evolution}} by {{Visualizing}} the {{Emergence}} of {{Topographic Mappings}}},
  author = {Brighton, Henry and Kirby, Simon},
  date = {2006},
  journaltitle = {Artificial Life},
  volume = {242},
  number = {2},
  pages = {229--242},
  keywords = {evolution,language,learning,replicators,visualization},
  file = {/Users/shanest/sync/library/Brighton/2006/Brighton - 2006 - Understanding Linguistic Evolution by Visualizing .pdf}
}

@inproceedings{chaabouniCompositionalityGeneralizationEmergent2020,
  title = {Compositionality and {{Generalization In Emergent Languages}}},
  booktitle = {Proceedings of the 58th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Chaabouni, Rahma and Kharitonov, Eugene and Bouchacourt, Diane and Dupoux, Emmanuel and Baroni, Marco},
  editor = {Jurafsky, Dan and Chai, Joyce and Schluter, Natalie and Tetreault, Joel},
  date = {2020-07},
  pages = {4427--4442},
  publisher = {{Association for Computational Linguistics}},
  location = {{Online}},
  doi = {10.18653/v1/2020.acl-main.407},
  abstract = {Natural language allows us to refer to novel composite concepts by combining expressions denoting their parts according to systematic rules, a property known as compositionality. In this paper, we study whether the language emerging in deep multi-agent simulations possesses a similar ability to refer to novel primitive combinations, and whether it accomplishes this feat by strategies akin to human-language compositionality. Equipped with new ways to measure compositionality in emergent languages inspired by disentanglement in representation learning, we establish three main results: First, given sufficiently large input spaces, the emergent language will naturally develop the ability to refer to novel composite concepts. Second, there is no correlation between the degree of compositionality of an emergent language and its ability to generalize. Third, while compositionality is not necessary for generalization, it provides an advantage in terms of language transmission: The more compositional a language is, the more easily it will be picked up by new learners, even when the latter differ in architecture from the original agents. We conclude that compositionality does not arise from simple generalization pressure, but if an emergent language does chance upon it, it will be more likely to survive and thrive.},
  eventtitle = {{{ACL}} 2020},
  file = {/Users/shanest/sync/library/Chaabouni et al/2020/Chaabouni et al. - 2020 - Compositionality and Generalization In Emergent La3.pdf}
}

@inproceedings{dziriFaithFateLimits2023,
  title = {Faith and {{Fate}}: {{Limits}} of {{Transformers}} on {{Compositionality}}},
  shorttitle = {Faith and {{Fate}}},
  author = {Dziri, Nouha and Lu, Ximing and Sclar, Melanie and Li, Xiang Lorraine and Jiang, Liwei and Lin, Bill Yuchen and Welleck, Sean and West, Peter and Bhagavatula, Chandra and Bras, Ronan Le and Hwang, Jena D. and Sanyal, Soumya and Ren, Xiang and Ettinger, Allyson and Harchaoui, Zaid and Choi, Yejin},
  date = {2023-11-02},
  url = {https://openreview.net/forum?id=Fkckkr3ya8&referrer=%5Bthe%20profile%20of%20Xiang%20Ren%5D(%2Fprofile%3Fid%3D~Xiang_Ren1)},
  urldate = {2024-03-18},
  abstract = {Transformer large language models (LLMs) have sparked admiration for their exceptional performance on tasks that demand intricate multi-step reasoning. Yet, these models simultaneously show failures on surprisingly trivial problems. This begs the question: Are these errors incidental, or do they signal more substantial limitations? In an attempt to demystify transformer LLMs, we investigate the limits of these models across three representative compositional tasks---multi-digit multiplication, logic grid puzzles, and a classic dynamic programming problem. These tasks require breaking problems down into sub-steps and synthesizing these steps into a precise answer. We formulate compositional tasks as computation graphs to systematically quantify the level of complexity, and break down reasoning steps into intermediate sub-procedures. Our empirical findings suggest that transformer LLMs solve compositional tasks by reducing multi-step compositional reasoning into linearized subgraph matching, without necessarily developing systematic problem-solving skills. To round off our empirical study, we provide theoretical arguments on abstract multi-step reasoning problems that highlight how autoregressive generations' performance can rapidly decay with increased task complexity.},
  eventtitle = {Thirty-Seventh {{Conference}} on {{Neural Information Processing Systems}}},
  langid = {english},
  file = {/Users/shanest/sync/library/Dziri et al/2023/Dziri et al. - 2023 - Faith and Fate Limits of Transformers on Composit.pdf}
}

@article{fodorConnectionismCognitiveArchitecture1988,
  title = {Connectionism and {{Cognitive Architecture}}},
  author = {Fodor, Jerry and Pylyshyn, Zenon W.},
  date = {1988},
  journaltitle = {Cognition},
  volume = {28},
  number = {1-2},
  pages = {3--71},
  doi = {10.1016/0010-0277(88)90031-5},
  abstract = {This paper explores differences between Connectionist proposals for cognitive architecture and the sorts of models that have traditionally been assumed in cognitive science. We claim that the major distinction is that, while both Connectionist and Classical architectures postulate representational mental states, the latter but not the former are committed to a symbol-level of representation, or to a ‘language of thought’: i.e., to representational states that have combinatorial syntactic and semantic structure. Several arguments for combinatorial structure in mental representations are then reviewed. These include arguments based on the ‘systematicity’ of mental representation: i.e., on the fact that cognitive capacities always exhibit certain symmetries, so that the ability to entertain a given thought implies the ability to entertain thoughts with semantically related contents. We claim that such arguments make a powerful case that mind/brain architecture is not Connectionist at the cognitive level. We then consider the possibility that Connectionism may provide an account of the neural (or ‘abstract neurological’) structures in which Classical cognitive architecture is implemented. We survey a number of the standard arguments that have been offered in favor of Connectionism, and conclude that they are coherent only on this interpretation.},
  file = {/Users/shanest/sync/library/Fodor_Pylyshyn/1988/Fodor and Pylyshyn - 1988 - Connectionism and Cognitive Architecture.pdf}
}

@article{hupkesCompositionalityDecomposedHow2020,
  title = {Compositionality {{Decomposed}}: {{How}} Do {{Neural Networks Generalise}}?},
  shorttitle = {Compositionality {{Decomposed}}},
  author = {Hupkes, Dieuwke and Dankers, Verna and Mul, Mathijs and Bruni, Elia},
  date = {2020-04-12},
  journaltitle = {Journal of Artificial Intelligence Research},
  volume = {67},
  pages = {757--795},
  issn = {1076-9757},
  doi = {10.1613/jair.1.11674},
  abstract = {Despite a multitude of empirical studies, little consensus exists on whether neural networks are able to generalise compositionally, a controversy that, in part, stems from a lack of agreement about what it means for a neural model to be compositional. As a response to this controversy, we present a set of tests that provide a bridge between, on the one hand, the vast amount of linguistic and philosophical theory about compositionality of language and, on the other, the successful neural models of language. We collect different interpretations of compositionality and translate them into five theoretically grounded tests for models that are formulated on a task-independent level. In particular, we provide tests to investigate (i) if models systematically recombine known parts and rules (ii) if models can extend their predictions beyond the length they have seen in the training data (iii) if models’ composition operations are local or global (iv) if models’ predictions are robust to synonym substitutions and (v) if models favour rules or exceptions during training. To demonstrate the usefulness of this evaluation paradigm, we instantiate these five tests on a highly compositional data set which we dub PCFG SET and apply the resulting tests to three popular sequence-to-sequence models: a recurrent, a convolution-based and a transformer model. We provide an in-depth analysis of the results, which uncover the strengths and weaknesses of these three architectures and point to potential areas of improvement.},
  langid = {english},
  keywords = {machine learning,natural language,neural networks,rule learning},
  file = {/Users/shanest/sync/library/Hupkes et al/2020/Hupkes et al. - 2020 - Compositionality Decomposed How do Neural Network.pdf}
}

@article{hupkesTaxonomyReviewGeneralization2023,
  title = {A Taxonomy and Review of Generalization Research in {{NLP}}},
  author = {Hupkes, Dieuwke and Giulianelli, Mario and Dankers, Verna and Artetxe, Mikel and Elazar, Yanai and Pimentel, Tiago and Christodoulopoulos, Christos and Lasri, Karim and Saphra, Naomi and Sinclair, Arabella and Ulmer, Dennis and Schottmann, Florian and Batsuren, Khuyagbaatar and Sun, Kaiser and Sinha, Koustuv and Khalatbari, Leila and Ryskina, Maria and Frieske, Rita and Cotterell, Ryan and Jin, Zhijing},
  date = {2023-10},
  journaltitle = {Nature Machine Intelligence},
  shortjournal = {Nat Mach Intell},
  volume = {5},
  number = {10},
  pages = {1161--1174},
  publisher = {{Nature Publishing Group}},
  issn = {2522-5839},
  doi = {10.1038/s42256-023-00729-y},
  abstract = {The ability to generalize well is one of the primary desiderata for models of natural language processing (NLP), but what ‘good generalization’ entails and how it should be evaluated is not well understood. In this Analysis we present a taxonomy for characterizing and understanding generalization research in NLP. The proposed taxonomy is based on an extensive literature review and contains five axes along which generalization studies can differ: their main motivation, the type of generalization they aim to solve, the type of data shift they consider, the source by which this data shift originated, and the locus of the shift within the NLP modelling pipeline. We use our taxonomy to classify over 700 experiments, and we use the results to present an in-depth analysis that maps out the current state of generalization research in NLP and make recommendations for which areas deserve attention in the future.},
  langid = {english},
  keywords = {Computer science,Language and linguistics},
  file = {/Users/shanest/sync/library/Hupkes et al/2023/Hupkes et al. - 2023 - A taxonomy and review of generalization research i.pdf}
}

@inproceedings{keysersMeasuringCompositionalGeneralization2019,
  title = {Measuring {{Compositional Generalization}}: {{A Comprehensive Method}} on {{Realistic Data}}},
  shorttitle = {Measuring {{Compositional Generalization}}},
  author = {Keysers, Daniel and Schärli, Nathanael and Scales, Nathan and Buisman, Hylke and Furrer, Daniel and Kashubin, Sergii and Momchev, Nikola and Sinopalnikov, Danila and Stafiniak, Lukasz and Tihon, Tibor and Tsarkov, Dmitry and Wang, Xiao and family=Zee, given=Marc, prefix=van, useprefix=false and Bousquet, Olivier},
  date = {2019-09-23},
  url = {https://openreview.net/forum?id=SygcCnNKwr},
  urldate = {2024-03-18},
  abstract = {State-of-the-art machine learning methods exhibit limited compositional generalization. At the same time, there is a lack of realistic benchmarks that comprehensively measure this ability, which makes it challenging to find and evaluate improvements. We introduce a novel method to systematically construct such benchmarks by maximizing compound divergence while guaranteeing a small atom divergence between train and test sets, and we quantitatively compare this method to other approaches for creating compositional generalization benchmarks. We present a large and realistic natural language question answering dataset that is constructed according to this method, and we use it to analyze the compositional generalization ability of three machine learning architectures. We find that they fail to generalize compositionally and that there is a surprisingly strong negative correlation between compound divergence and accuracy. We also demonstrate how our method can be used to create new compositionality benchmarks on top of the existing SCAN dataset, which confirms these findings.},
  eventtitle = {International {{Conference}} on {{Learning Representations}}},
  langid = {english},
  file = {/Users/shanest/sync/library/Keysers et al/2019/Keysers et al. - 2019 - Measuring Compositional Generalization A Comprehe.pdf}
}

@inproceedings{kimCOGSCompositionalGeneralization2020,
  title = {{{COGS}}: {{A Compositional Generalization Challenge Based}} on {{Semantic Interpretation}}},
  shorttitle = {{{COGS}}},
  booktitle = {Proceedings of the 2020 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  author = {Kim, Najoung and Linzen, Tal},
  editor = {Webber, Bonnie and Cohn, Trevor and He, Yulan and Liu, Yang},
  date = {2020-11},
  pages = {9087--9105},
  publisher = {{Association for Computational Linguistics}},
  location = {{Online}},
  doi = {10.18653/v1/2020.emnlp-main.731},
  abstract = {Natural language is characterized by compositionality: the meaning of a complex expression is constructed from the meanings of its constituent parts. To facilitate the evaluation of the compositional abilities of language processing architectures, we introduce COGS, a semantic parsing dataset based on a fragment of English. The evaluation portion of COGS contains multiple systematic gaps that can only be addressed by compositional generalization; these include new combinations of familiar syntactic structures, or new combinations of familiar words and familiar structures. In experiments with Transformers and LSTMs, we found that in-distribution accuracy on the COGS test set was near-perfect (96–99\%), but generalization accuracy was substantially lower (16–35\%) and showed high sensitivity to random seed (+-6–8\%). These findings indicate that contemporary standard NLP models are limited in their compositional generalization capacity, and position COGS as a good way to measure progress.},
  eventtitle = {{{EMNLP}} 2020},
  file = {/Users/shanest/Zotero/storage/GRNZJHYS/Kim and Linzen - 2020 - COGS A Compositional Generalization Challenge Bas.pdf}
}

@inproceedings{lakeGeneralizationSystematicityCompositional2018,
  title = {Generalization without {{Systematicity}}: {{On}} the {{Compositional Skills}} of {{Sequence-to-Sequence Recurrent Networks}}},
  shorttitle = {Generalization without {{Systematicity}}},
  booktitle = {Proceedings of the 35th {{International Conference}} on {{Machine Learning}}},
  author = {Lake, Brenden and Baroni, Marco},
  date = {2018-07-03},
  pages = {2873--2882},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v80/lake18a.html},
  urldate = {2024-03-18},
  abstract = {Humans can understand and produce new utterances effortlessly, thanks to their compositional skills. Once a person learns the meaning of a new verb "dax," he or she can immediately understand the meaning of "dax twice" or "sing and dax." In this paper, we introduce the SCAN domain, consisting of a set of simple compositional navigation commands paired with the corresponding action sequences. We then test the zero-shot generalization capabilities of a variety of recurrent neural networks (RNNs) trained on SCAN with sequence-to-sequence methods. We find that RNNs can make successful zero-shot generalizations when the differences between training and test commands are small, so that they can apply "mix-and-match" strategies to solve the task. However, when generalization requires systematic compositional skills (as in the "dax" example above), RNNs fail spectacularly. We conclude with a proof-of-concept experiment in neural machine translation, suggesting that lack of systematicity might be partially responsible for neural networks’ notorious training data thirst.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {/Users/shanest/Zotero/storage/6ZINYTDA/Lake and Baroni - 2018 - Generalization without Systematicity On the Compo.pdf;/Users/shanest/Zotero/storage/T8QQKZL9/Lake and Baroni - 2018 - Generalization without Systematicity On the Compo.pdf}
}

@article{lakeHumanlikeSystematicGeneralization2023a,
  title = {Human-like Systematic Generalization through a Meta-Learning Neural Network},
  author = {Lake, Brenden M. and Baroni, Marco},
  date = {2023-11},
  journaltitle = {Nature},
  volume = {623},
  number = {7985},
  pages = {115--121},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/s41586-023-06668-3},
  abstract = {The power of human language and thought arises from systematic compositionality—the algebraic ability to understand and produce novel combinations from known components. Fodor and Pylyshyn1 famously argued that artificial neural networks lack this capacity and are therefore not viable models of the mind. Neural networks have advanced considerably in the years since, yet the systematicity challenge persists. Here we successfully address Fodor and Pylyshyn’s challenge by providing evidence that neural networks can achieve human-like systematicity when optimized for their compositional skills. To do so, we introduce the meta-learning for compositionality (MLC) approach for guiding training through a dynamic stream of compositional tasks. To compare humans and machines, we conducted human behavioural experiments using an~instruction learning paradigm. After considering seven different models, we found that, in contrast to perfectly systematic but rigid probabilistic symbolic models, and perfectly flexible but unsystematic neural networks, only MLC achieves both the systematicity and flexibility needed for human-like generalization. MLC also advances the compositional skills of machine learning systems in several systematic generalization benchmarks. Our results show how a standard neural network architecture, optimized for its compositional skills, can mimic human systematic generalization in a head-to-head comparison.},
  langid = {english},
  keywords = {Computer science,Human behaviour},
  file = {/Users/shanest/Zotero/storage/6L7QVKX3/Lake and Baroni - 2023 - Human-like systematic generalization through a met.pdf}
}

@inproceedings{liSLOGStructuralGeneralization2023,
  title = {{{SLOG}}: {{A Structural Generalization Benchmark}} for {{Semantic Parsing}}},
  shorttitle = {{{SLOG}}},
  booktitle = {Proceedings of the 2023 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Li, Bingzhi and Donatelli, Lucia and Koller, Alexander and Linzen, Tal and Yao, Yuekun and Kim, Najoung},
  editor = {Bouamor, Houda and Pino, Juan and Bali, Kalika},
  date = {2023-12},
  pages = {3213--3232},
  publisher = {{Association for Computational Linguistics}},
  location = {{Singapore}},
  doi = {10.18653/v1/2023.emnlp-main.194},
  abstract = {The goal of compositional generalization benchmarks is to evaluate how well models generalize to new complex linguistic expressions. Existing benchmarks often focus on lexical generalization, the interpretation of novel lexical items in syntactic structures familiar from training; structural generalization tasks, where a model needs to interpret syntactic structures that are themselves unfamiliar from training, are often underrepresented, resulting in overly optimistic perceptions of how well models can generalize. We introduce SLOG, a semantic parsing dataset that extends COGS (Kim and Linzen, 2020) with 17 structural generalization cases. In our experiments, the generalization accuracy of Transformer models, including pretrained ones, only reaches 40.6\%, while a structure-aware parser only achieves 70.8\%. These results are far from the near-perfect accuracy existing models achieve on COGS, demonstrating the role of SLOG in foregrounding the large discrepancy between models' lexical and structural generalization capacities.},
  eventtitle = {{{EMNLP}} 2023},
  file = {/Users/shanest/sync/library/Li et al/2023/Li et al. - 2023 - SLOG A Structural Generalization Benchmark for Se.pdf}
}

@article{paginCompositionalityDefinitionsVariants2010,
  title = {Compositionality {{I}}: {{Definitions}} and {{Variants}}.},
  author = {Pagin, Peter and Westerståhl, Dag},
  date = {2010},
  journaltitle = {Philosophy Compass},
  volume = {5},
  number = {3},
  pages = {250--264},
  doi = {10.1111/j.1747-9991.2009.00228.x},
  abstract = {This is the first part of a two-part article on semantic compositionality, that is, the principle that the meaning of a complex expression is determined by the meanings of its parts and the way they are put together. Here we provide a brief historical background, a formal framework for syntax and semantics, precise definitions, and a survey of variants of compositionality. Stronger and weaker forms are distinguished, as well as generalized forms that cover extra-linguistic context dependence as well as linguistic context dependence. In the second article, we survey arguments for and arguments against the claim that natural languages are compositional, and consider some problem cases. It will be referred to as Part II.},
  file = {/Users/shanest/sync/library/Pagin_Westerstr a hl/2010/Pagin and Westerstr a hl - 2010 - Compositionality I Definitions and Variants..pdf}
}

@article{paginCompositionalityIIArguments2010,
  title = {Compositionality {{II}}: {{Arguments}} and {{Problems}}.},
  author = {Pagin, Peter and Westerståhl, Dag},
  date = {2010},
  journaltitle = {Philosophy Compass},
  volume = {5},
  number = {3},
  pages = {265--282},
  doi = {10.1111/j.1747-9991.2009.00229.x},
  abstract = {This is the second part of a two-part article on compositionality, i.e. the principle that the meaning of a complex expression is determined by the meanings of its parts and the way they are put together. In the first, Pagin and Westerståhl (2010), we provide a general historical background, a formal framework, definitions, and a survey of variants of compositionality. It will be referred to as Part I. Here we discuss arguments for and against the claim that natural languages have a compositional semantics. We also discuss some problem cases, including belief reports, quotation, idioms, and ambiguity.},
  file = {/Users/shanest/sync/library/Pagin_Westerstr a hl/2010/Pagin and Westerstr a hl - 2010 - Compositionality II Arguments and Problems..pdf}
}

@article{pottsCaseDeepLearning2019,
  title = {A Case for Deep Learning in Semantics: {{Response}} to {{Pater}}},
  shorttitle = {A Case for Deep Learning in Semantics},
  author = {Potts, Christopher},
  date = {2019},
  journaltitle = {Language},
  volume = {95},
  number = {1},
  pages = {e115-e124},
  publisher = {{Linguistic Society of America}},
  issn = {1535-0665},
  doi = {10.1353/lan.2019.0019},
  abstract = {Pater’s (2019) target article builds a persuasive case for establishing stronger ties between theoretical linguistics and connectionism (deep learning). This commentary extends his arguments to semantics, focusing in particular on issues of learning, compositionality, and lexical meaning.*},
  keywords = {compositionality,connectionism,deep learning,lexical semantics,machine learning,position,semantics,survey},
  file = {/Users/shanest/sync/library/Potts/2019/Potts - 2019 - A case for deep learning in semantics Response to2.pdf}
}

@article{smithLinguisticStructureEvolutionary2013,
  title = {Linguistic Structure Is an Evolutionary Trade-off between Simplicity and Expressivity},
  author = {Smith, Kenny and Tamariz, Monica and Kirby, Simon},
  date = {2013},
  journaltitle = {Proceedings of the 35th Annual Meeting of the Cognitive Science Society},
  pages = {1348--1353},
  abstract = {Language exhibits structure: a species-unique system for expressing complex meanings using complex forms. We present a review of modelling and experimental literature on the evolution of structure which suggests that structure is a cultural adaptation in response to pressure for expressivity (arising during communication) and compressibility (arising during learning), and test this hypothesis using a new Bayesian iterated learning model. We conclude that linguistic structure can and should be explained as a consequence of cultural evolution in response to these two pressures.},
  keywords = {cultural evolution,language,learning,structure},
  file = {/Users/shanest/sync/library/Smith et al/2013/Smith et al. - 2013 - Linguistic structure is an evolutionary trade-off .pdf}
}

@article{steinert-threlkeldEmergenceNontrivialCompositionality2020,
  title = {Toward the {{Emergence}} of {{Nontrivial Compositionality}}},
  author = {Steinert-Threlkeld, Shane},
  date = {2020},
  journaltitle = {Philosophy of Science},
  volume = {87},
  number = {5},
  pages = {897--909},
  publisher = {{The University of Chicago Press}},
  issn = {0031-8248},
  doi = {10.1086/710628},
  abstract = {All natural languages exhibit a distinction between content words (nouns, verbs, etc.) and function words (determiners, auxiliaries, tenses, etc.). Yet surprisingly little has been said about the emergence of this universal architectural feature of human language. This article argues that the existence of this distinction requires the presence of nontrivial compositionality and identifies assumptions that have previously been made in the literature that provably guarantee only trivial composition. It then presents a signaling game with variable contexts and shows how the distinction can emerge via reinforcement learning.},
  keywords = {Artificial Intelligence,Cognitive Science,evolution,function,games,language,learning,networks,neural,of,reinforcement,signaling,words},
  file = {/Users/shanest/sync/library/Steinert-Threlkeld/2020/Steinert-Threlkeld - 2020 - Towards the Emergence of Non-trivial Compositional.pdf;/Users/shanest/Zotero/storage/QNZQKBGP/Steinert-Threlkeld - 2020 - Toward the Emergence of Nontrivial Compositionalit.pdf}
}

@article{szaboCompositionality2022,
  title = {Compositionality},
  author = {Szabó, Zoltán Gendler},
  editor = {Zalta, Edward N},
  date = {2022},
  journaltitle = {The Stanford Encyclopedia of Philosophy},
  volume = {Fall},
  url = {https://plato.stanford.edu/archives/fall2022/entries/compositionality/}
}
